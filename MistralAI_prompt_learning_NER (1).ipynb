{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-vW7JfXS2RD",
        "outputId": "d567ad73-18b5-4702-8cc6-4c05a2760ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-0.1.3-py3-none-any.whl (15 kB)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<16.0.0,>=15.0.0 (from mistralai)\n",
            "  Downloading pyarrow-15.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.2.0->mistralai) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.2.0->mistralai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.2.0->mistralai) (2023.4)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.2.0->mistralai)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.0->mistralai) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai) (1.2.0)\n",
            "Installing collected packages: tzdata, pyarrow, orjson, h11, pandas, httpcore, httpx, mistralai\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.25.2 mistralai-0.1.3 orjson-3.9.15 pandas-2.2.1 pyarrow-15.0.1 tzdata-2024.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chriswu99aaa/MeTNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwJmwE-5g1jD",
        "outputId": "09486f7d-aad4-4270-afb1-0a8f4c944371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MeTNet'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 241 (delta 6), reused 0 (delta 0), pack-reused 228\u001b[K\n",
            "Receiving objects: 100% (241/241), 32.24 MiB | 16.25 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MISTRAL_API_KEY'] = 'MY-API-KEY'"
      ],
      "metadata": {
        "id": "rcryPR-HUKtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        "model = \"mistral-medium\"\n",
        "\n",
        "client = MistralClient(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "75f3qxKdS8S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data and Preprocessing"
      ],
      "metadata": {
        "id": "Usv_5PBggtuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_file(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            if '\\t' in line:\n",
        "                token, tag = line.split('\\t')\n",
        "                tokens.append(token)\n",
        "                tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs"
      ],
      "metadata": {
        "id": "gIBmm9JRaeXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, train_tags = read_file('/content/MeTNet/data/Few-COMM/train.txt')\n",
        "\n",
        "texts, tags = read_file('/content/MeTNet/data/Few-COMM/dev.txt')\n",
        "\n",
        "test_text, test_tags = read_file('/content/MeTNet/data/Few-COMM/test.txt')"
      ],
      "metadata": {
        "id": "Go5iNZl_g3-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get tags from tow datasets and union the two sets\n",
        "unique_tags = set(tag for doc in train_tags for tag in doc)\n",
        "unique_tags_val = set(tag for doc in tags for tag in doc)\n",
        "unique_tags = unique_tags | unique_tags_val\n",
        "\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ],
      "metadata": {
        "id": "QYhxwfLhhAOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the first query data\n",
        "query_texts = texts[:200][:]\n",
        "query_tags = tags[:200][:]"
      ],
      "metadata": {
        "id": "DVWQc3LjhC0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = query_texts[0]\n",
        "query_tag = query_tags[0]"
      ],
      "metadata": {
        "id": "Sm0oSlZIhHkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = ''.join(query)"
      ],
      "metadata": {
        "id": "a24TtkFfmeZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LykCIebrmxoc",
        "outputId": "add02a07-be19-46e2-d731-679ced5439c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'味可滋冷萃奶茶/250ml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing Prompt"
      ],
      "metadata": {
        "id": "B6sHMQXrhey6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "example_query = \"\"\"维\tO\n",
        "他\tO\n",
        "和\tO\n",
        "梨\tO\n",
        "饮\tO\n",
        "料\tO\n",
        "2\tO\n",
        "5\tO\n",
        "0\tO\n",
        "m\tO\n",
        "l\tO\n",
        "*\tO\n",
        "6\tO\n",
        "盒\tO\n",
        "/\tO\n",
        "组\tO\n",
        "（\tO\n",
        "香\tB-原产地\n",
        "港\tI-原产地\n",
        "进\tI-原产地\n",
        "口\tI-原产地\n",
        "）\tO\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "W05E6Re-hSTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. extract an example for each label\n",
        "2. create a dictionary dict{word: tag}\n",
        "3. put example according to its id. i.e Label A has id 3, then intext_mapping[3] will have an example text"
      ],
      "metadata": {
        "id": "9dQ30fXiohBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id['I-适用性别']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tH2xDbgqqKq",
        "outputId": "4c7bcf62-bcc6-43a8-d553-c78d1deb7d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_query_tags = len(unique_tags)"
      ],
      "metadata": {
        "id": "qHyAKg2Tv1Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mapping = {}\n",
        "assigned = [0]*num_query_tags\n",
        "\n"
      ],
      "metadata": {
        "id": "Mq8Tc0uWm-KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling each class with one entity\n",
        "test_tags = query_tags[:8000]\n",
        "for i in range(len(test_tags)):\n",
        "    tag = test_tags[i]\n",
        "    for j in range(len(tag)):\n",
        "        if tag[j] != 'O':\n",
        "            # the index corresponds to the id of the tag\n",
        "            id = tag2id[tag[j]]\n",
        "            word = query_texts[i][j]\n",
        "            if assigned[id] == 0:\n",
        "                # give one example for each class\n",
        "                text_mapping[word] = tag[j]\n",
        "                assigned[id] = 1\n",
        "                print(text_mapping[word])\n",
        "                print(id)\n"
      ],
      "metadata": {
        "id": "2pvTVcccnW8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mapping = str(text_mapping).replace(':','')"
      ],
      "metadata": {
        "id": "80Ag_EyrwbCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "    You are a Chinese Named Entity Recognizer. The input data is in Chinese and the\n",
        "    data is annotated in BIO scheme.\n",
        "    The full list of BIO Tags are provided in the following part delimeted by triple #\n",
        "    ###\n",
        "    'B-国产/进口','B-适用人群','I-适用人群','B-适用空间','I-版型','B-面料材质','B-产地','B-酸碱度',\n",
        "    'B-果肉颜色','B-锅底类型','B-是否去骨','I-适用空间','I-是否有机','B-外观','B-袖长','I-长短','B-组合形式', 'I-送礼对象',\n",
        "    'I-袖型','I-型号','B-型号','B-形状形态','I-接口','I-是否净洗','I-供电方式','B-送礼对象','B-是否去皮','B-是否净洗','I-适用人数',\n",
        "    'I-定制服务','B-定制服务','I-适用对象','B-供电方式','I-产地','I-配件类型','I-脂肪含量','I-大小','B-其他属性','O','B-厚薄',\n",
        "    'I-糖含量','I-面料材质','I-袖长','I-造型','I-颜色','I-是否去骨','B-赠品','I-其他属性', 'I-品质等级','I-适用运营商','I-组合形式',\n",
        "    'I-果肉颜色','B-接口','I-功能功效','B-适用人数','B-版型','B-材质','I-厚度','B-功能功效','B-长短' 'B-造型','I-成分','I-填充材质',\n",
        "    'I-是否去皮','B-适用衣物','I-国产/进口','I-鞋垫材质','B-填充材质', 'B-运输服务',\n",
        "    'I-控制方式', 'I-适用衣物','B-品质等级','B-适用运营商','B-适用对象','I-存储容量','I-香型','I-运输服务','I-商品特色',\n",
        "    'B-脂肪含量','I-厚薄','B-控制方式','B-筒高','I-长度','I-外观','B-领型','B-分类','I-适用季节','B-适用季节','B-糖含量','B-存储容量',\n",
        "    'I-分类','B-商品特色','I-赠品','B-香型','B-是否有机','I-材质','I-酸碱度','B-厚度','B-礼盒类型','I-筒高','B-袖型','I-形状形态',\n",
        "    'B-成分','B-大小','I-领型','B-鞋垫材质','B-长度', 'I-锅底类型', 'B-配件类型', 'B-颜色',\n",
        "    'I-礼盒类型'\n",
        "    ###\n",
        "'''\n",
        "    An example  of character and its BIO tag is provided in the delimeter triple #\n",
        "    ###\n",
        "    {text_mapping}\n",
        "    ###\n",
        "    When giving a input setence in chinese classify each character\n",
        "    using the following format\n",
        "    character BIOtag\n",
        "    If input has number and symbols, keep number and symbols in the output\n",
        "\n",
        "\n",
        "    If all characters are tagged as O class, provide the output without include an explanation or notification\n",
        "    provide only the word and tag in the ouptut, and nothing else.\n",
        "    remove your Note from your response\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MyQ8RhEvhUaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    ChatMessage(role='system', content=system_prompt),\n",
        "    ChatMessage(role=\"user\", content='清真肉串')\n",
        "]\n",
        "\n",
        "# No streaming\n",
        "chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "result = chat_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "L_jYXre3hb4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2b1BNWj-FOPa",
        "outputId": "69b79a6c-72a6-41fb-f28c-9c9c2257be66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"清 'B-是否清真'\\n真 'I-是否清真'\\n肉 'B-适用运营商'\\n串 'I-商品特色'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "result = re.split('\\n',result)\n"
      ],
      "metadata": {
        "id": "_anbfjhE3fu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = [re.split(' ',line) for line in result]"
      ],
      "metadata": {
        "id": "i2tfxzvWZKiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhD2pOlZXN_Q",
        "outputId": "9eeec4b2-48ee-4983-f892-a89e00aac3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['清', \"'B-是否清真'\"], ['真', \"'I-是否清真'\"], ['肉', \"'B-适用运营商'\"], ['串', \"'I-商品特色'\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_format(result):\n",
        "    for i in range(len(result)):\n",
        "        if '' in result[i]:\n",
        "            result.pop()\n",
        "            result.pop()\n",
        "            break\n",
        "    return result"
      ],
      "metadata": {
        "id": "Zq-vaOee4B4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = check_format(test_result)"
      ],
      "metadata": {
        "id": "Nn3YXFzWYX6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngh5tz2FZy3R",
        "outputId": "cbfcc4cf-b73e-45f2-cdff-273614e8e95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['清', \"'B-是否清真'\"], ['真', \"'I-是否清真'\"], ['肉', \"'B-适用运营商'\"], ['串', \"'I-商品特色'\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "lampxPC128M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "def compute_metrics(preds, labels):\n",
        "    \"\"\"\n",
        "    This function computes the confusion matrix for the given prediction and label\n",
        "    \"\"\"\n",
        "\n",
        "    return f1_score(labels,preds,average='micro')\n",
        "\n",
        "def average_f1(f1_list):\n",
        "    return statistics.mean(f1_list)"
      ],
      "metadata": {
        "id": "ii-OsYcTiq_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_key(dict, predictions):\n",
        "    \"\"\"\n",
        "    this function convert prediction to its id\n",
        "    by checking if the tag exists; otherwise assign to\n",
        "    O-class\n",
        "\n",
        "    dict: the tag2id dictionary\n",
        "    predictions: the list of prediciton\n",
        "    \"\"\"\n",
        "    for i in range(len(predictions)):\n",
        "        pred = predictions[i]\n",
        "        # print(pred)\n",
        "        if pred in dict.keys():\n",
        "            # print(pred, ' in map')\n",
        "            predictions[i] = dict[pred]\n",
        "        else:\n",
        "            predictions[i] = dict['O']\n",
        "    return predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "KYbq-E873ABr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dimension(preds, labels):\n",
        "    '''\n",
        "    This function validate size of two input to check if they\n",
        "    have the same size; otherwise, it drim the list from the back.\n",
        "\n",
        "    '''\n",
        "    if len(preds) == len(labels):\n",
        "        return preds, labels\n",
        "    else:\n",
        "        len_p = len(preds)\n",
        "        len_l = len(labels)\n",
        "        if len_p > len_l:\n",
        "# if length of prediction is longer than the label, remove those extra elements\n",
        "            preds = preds[:len_l]\n",
        "            return preds, labels\n",
        "        else:\n",
        "            labels = labels[:len_p]\n",
        "            return preds, labels"
      ],
      "metadata": {
        "id": "gsPMlTrZ3ELa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Shot"
      ],
      "metadata": {
        "id": "7Mao32xh3IZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_texts = test_texts[:8000][:]\n",
        "query_tags = test_tags[:8000][:]"
      ],
      "metadata": {
        "id": "lzvylDYY5ONK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "\n"
      ],
      "metadata": {
        "id": "pftaRH3Aczv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200,len(query_texts)):\n",
        "    print(i)\n",
        "\n",
        "    query = query_texts[i]\n",
        "    query = ' '.join(query)\n",
        "    true_label = query_tags[i]\n",
        "\n",
        "\n",
        "    messages = [\n",
        "    ChatMessage(role='system', content=system_prompt),\n",
        "    ChatMessage(role=\"user\", content=query)\n",
        "    ]\n",
        "\n",
        "    # No streaming\n",
        "    chat_response = client.chat(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "        # temperature=0.2\n",
        "    )\n",
        "\n",
        "\n",
        "    result = chat_response.choices[0].message.content\n",
        "\n",
        "    result = re.split('\\n',result)\n",
        "    result = [re.split('[ \\t]',line) for line in result]\n",
        "    print(result)\n",
        "    result = check_format(result)\n",
        "\n",
        "\n",
        "    pred = [line[1] for line in result]\n",
        "    pred = check_key(tag2id,pred)\n",
        "\n",
        "    # convert tag to id for f1 score calculation\n",
        "    true_label = [int(tag2id[tag]) for tag in true_label]\n",
        "\n",
        "    # validate input\n",
        "    pred, true_label = validate_dimension(pred, true_label)\n",
        "\n",
        "    f1 = compute_metrics(true_label, pred)\n",
        "    if f1 < 0.4:\n",
        "        # record those low f1_score prediction for error analysis\n",
        "        id_list.append(i)\n",
        "        pred_list.append(word_pred)\n",
        "        low_f1_list.append(f1)\n",
        "    f1_scores.append(f1)\n",
        "\n"
      ],
      "metadata": {
        "id": "cMLtLRLJ3E7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"One shot :\",average_f1(f1_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IKVq1cGjveZ",
        "outputId": "f822daf1-4e11-4d20-d1b9-a56ccad330c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.670989257213999"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Five Shots"
      ],
      "metadata": {
        "id": "1x8T3VCJ1uMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_shot_f1_scores = []\n"
      ],
      "metadata": {
        "id": "B8_jmCkz1vrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_query_tags = len(unique_tags)\n",
        "text_mapping = {}\n",
        "assigned = [0]*num_query_tags\n"
      ],
      "metadata": {
        "id": "GakI9tCt18y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling five instance for each class\n",
        "test_tags = query_tags[:8000]\n",
        "for i in range(len(test_tags)):\n",
        "    tag = test_tags[i]\n",
        "    for j in range(len(tag)):\n",
        "        if tag[j] != 'O':\n",
        "            # the index corresponds to the id of the tag\n",
        "            id = tag2id[tag[j]]\n",
        "            word = query_texts[i][j]\n",
        "            if assigned[id] < 5:\n",
        "                if assigned[id] == 0:\n",
        "                    word_list = [word]\n",
        "                    text_mapping[tag[j]] = word_list\n",
        "                    assigned[id] += 1\n",
        "                else:\n",
        "                    word_list = text_mapping[tag[j]]\n",
        "                    if word not in word_list:\n",
        "                        word_list.append(word)\n",
        "                        assigned[id] += 1\n",
        "                    text_mapping[tag[j]] = word_list\n",
        "\n"
      ],
      "metadata": {
        "id": "tUdQ7c9u2SUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58d4kdaTs8VB",
        "outputId": "f4ab6268-f93d-4d8a-ed1b-70cc71394f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-冲泡方式': ['冷'],\n",
              " 'I-冲泡方式': ['萃'],\n",
              " 'B-适用时间': ['端', '夏', '女', '初', '毕'],\n",
              " 'I-适用时间': ['午', '节', '天', '神', '秋'],\n",
              " 'B-适用性别': ['女', '男'],\n",
              " 'I-适用性别': ['孩', '司', '机', '女', '通'],\n",
              " 'B-粗细': ['细', '圆'],\n",
              " 'I-粗细': ['粉', '条'],\n",
              " 'B-色系': ['香'],\n",
              " 'I-色系': ['槟', '色', '系', '可', '选'],\n",
              " 'B-保质期': ['六'],\n",
              " 'I-保质期': ['个', '月', '以', '上'],\n",
              " 'B-风味': ['港', '戚', '老', '风', '苏'],\n",
              " 'I-风味': ['式', '风', '味'],\n",
              " 'B-适用生肖': ['兔', '猴'],\n",
              " 'I-适用生肖': ['子'],\n",
              " 'B-连接方式': ['光', '有', 'a', '无'],\n",
              " 'I-连接方式': ['纤', '线', 'u', 'x', '限'],\n",
              " 'B-加热方式': ['快', '煤', '燃', '双'],\n",
              " 'I-加热方式': ['速', '电', '热', '气', '面'],\n",
              " 'B-剂型': ['颗', '微', '含', '圆'],\n",
              " 'I-剂型': ['粒', '颗', '片'],\n",
              " 'B-甜度': ['无', '甜', '好', '干', '纯'],\n",
              " 'I-甜度': ['糖', '度', '高', '吃', '型'],\n",
              " 'B-适用车型': ['轿', 's', '丰', '比', '货'],\n",
              " 'I-适用车型': ['车', 'u', 'v', '田', '亚'],\n",
              " 'B-是否清真': ['清'],\n",
              " 'I-是否清真': ['真'],\n",
              " 'B-系列': ['甄', '满', '特', '小', '超'],\n",
              " 'I-系列': ['选', '钻', '享', '猪', '佩'],\n",
              " 'B-是否带盖': ['带', '可'],\n",
              " 'I-是否带盖': ['盖', '子'],\n",
              " 'B-裙型': ['小', '拼', '公'],\n",
              " 'I-裙型': ['黑', '裙', '接', '款', '主'],\n",
              " 'B-内容': ['女'],\n",
              " 'I-内容': ['司', '机']}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assigned"
      ],
      "metadata": {
        "id": "BAUYx0_CtJq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mapping = str(text_mapping)"
      ],
      "metadata": {
        "id": "V4FzRRCK2ekW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "    You are a Chinese Named Entity Recognizer. The input data is in Chinese and the\n",
        "    data is annotated in BIO scheme.\n",
        "    The full list of BIO Tags are provided in the following part delimeted by triple #\n",
        "    ###\n",
        "    'B-国产/进口','B-适用人群','I-适用人群','B-适用空间','I-版型','B-面料材质','B-产地','B-酸碱度',\n",
        "    'B-果肉颜色','B-锅底类型','B-是否去骨','I-适用空间','I-是否有机','B-外观','B-袖长','I-长短','B-组合形式', 'I-送礼对象',\n",
        "    'I-袖型','I-型号','B-型号','B-形状形态','I-接口','I-是否净洗','I-供电方式','B-送礼对象','B-是否去皮','B-是否净洗','I-适用人数',\n",
        "    'I-定制服务','B-定制服务','I-适用对象','B-供电方式','I-产地','I-配件类型','I-脂肪含量','I-大小','B-其他属性','O','B-厚薄',\n",
        "    'I-糖含量','I-面料材质','I-袖长','I-造型','I-颜色','I-是否去骨','B-赠品','I-其他属性', 'I-品质等级','I-适用运营商','I-组合形式',\n",
        "    'I-果肉颜色','B-接口','I-功能功效','B-适用人数','B-版型','B-材质','I-厚度','B-功能功效','B-长短' 'B-造型','I-成分','I-填充材质',\n",
        "    'I-是否去皮','B-适用衣物','I-国产/进口','I-鞋垫材质','B-填充材质', 'B-运输服务',\n",
        "    'I-控制方式', 'I-适用衣物','B-品质等级','B-适用运营商','B-适用对象','I-存储容量','I-香型','I-运输服务','I-商品特色',\n",
        "    'B-脂肪含量','I-厚薄','B-控制方式','B-筒高','I-长度','I-外观','B-领型','B-分类','I-适用季节','B-适用季节','B-糖含量','B-存储容量',\n",
        "    'I-分类','B-商品特色','I-赠品','B-香型','B-是否有机','I-材质','I-酸碱度','B-厚度','B-礼盒类型','I-筒高','B-袖型','I-形状形态',\n",
        "    'B-成分','B-大小','I-领型','B-鞋垫材质','B-长度', 'I-锅底类型', 'B-配件类型', 'B-颜色',\n",
        "    'I-礼盒类型'\n",
        "    ###\n",
        "'''\n",
        "    An example  of character and its BIO tag is provided in the delimeter triple #\n",
        "    ###\n",
        "    {text_mapping}\n",
        "    ###\n",
        "    When giving a input setence in chinese classify each character\n",
        "    using the following format\n",
        "    character BIOtag\n",
        "    If input has number and symbols, keep number and symbols in the output\n",
        "\n",
        "\n",
        "    If all characters are tagged as O class, provide the output without include an explanation or notification\n",
        "    provide only the word and tag in the ouptut, and nothing else.\n",
        "    remove your Note from your response\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eQRJOV7D2flA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_format(result):\n",
        "    for i in range(len(result)):\n",
        "        if '' in result[i]:\n",
        "            result.pop()\n",
        "            result.pop()\n",
        "            break\n",
        "    for i in range(len(result)):\n",
        "        for j in range(len(result[i])):\n",
        "            if (result[i][j]) == 1:\n",
        "                result.pop(i)\n",
        "    return result"
      ],
      "metadata": {
        "id": "-7lwlyS965cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "five_shot_query_texts = test_texts[:8000][:]\n",
        "five_shot_query_tags = test_tags[:8000][:]"
      ],
      "metadata": {
        "id": "42rsFKMX41Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# id list which record id of those prediction f1 scores lower than 0.4\n",
        "# pred list will record the prediction from LLM\n",
        "id_list = []\n",
        "pred_list = []\n",
        "low_f1_list = []"
      ],
      "metadata": {
        "id": "15PT5ZDJfaSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(five_shot_query_texts)):\n",
        "    print(i)\n",
        "\n",
        "    query = five_shot_query_texts[i]\n",
        "    query = ' '.join(query)\n",
        "    true_label = five_shot_query_tags[i]\n",
        "\n",
        "\n",
        "    messages = [\n",
        "    ChatMessage(role='system', content=system_prompt),\n",
        "    ChatMessage(role=\"user\", content=query)\n",
        "    ]\n",
        "\n",
        "    # No streaming\n",
        "    chat_response = client.chat(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "\n",
        "    result = chat_response.choices[0].message.content\n",
        "\n",
        "    result = re.split('\\n',result)\n",
        "    result = [re.split('[ \\t]',line) for line in result]\n",
        "    print(result)\n",
        "    result = check_format(result)\n",
        "\n",
        "\n",
        "    word_pred = [line[1] for line in result]\n",
        "    pred = check_key(tag2id,word_pred)\n",
        "\n",
        "    # convert tag to id for f1 score calculation\n",
        "    true_label = [int(tag2id[tag]) for tag in true_label]\n",
        "\n",
        "    # validate input\n",
        "    prediction, true_label = validate_dimension(pred, true_label)\n",
        "    f1 = compute_metrics(true_label, prediction)\n",
        "\n",
        "    if f1 < 0.4:\n",
        "        # record those low f1_score prediction for error analysis\n",
        "        id_list.append(i)\n",
        "        pred_list.append(word_pred)\n",
        "        low_f1_list.append(f1)\n",
        "    five_shot_f1_scores.append(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkbxPizc4-K-",
        "outputId": "c9745df0-1ea0-41fa-91e2-3b0418924c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197\n",
            "[['b', '-', '百', 'B-其他属性'], ['事', '-', '事', 'O'], ['可', '-', '可', 'O'], ['乐', '-', '乐', 'O'], ['无', '-', '无', 'B-糖含量'], ['糖', '-', '糖', 'I-糖含量'], ['树', '-', '树', 'B-果肉颜色'], ['莓', '-', '莓', 'I-果肉颜色'], ['味', '-', '味', 'O'], ['碳', '-', '碳', 'B-酸碱度'], ['酸', '-', '酸', 'I-酸碱度'], ['汽', '-', '汽', 'B-供电方式'], ['水', '-', '水', 'I-供电方式'], ['饮', '-', '饮', 'B-其他属性'], ['料', '-', '料', 'I-其他属性'], ['5', '-', '5', 'O'], ['0', '-', '0', 'O'], ['0', '-', '0', 'O'], ['m', '-', 'm', 'O'], ['l', '-', 'l', 'O'], ['/', '-', '/', 'O'], ['1', '-', '1', 'O'], ['瓶', '-', '瓶', 'B-其他属性'], ['/', '-', '/', 'O'], ['份', '-', '份', 'I-其他属性']]\n",
            "198\n",
            "[['单', 'O'], ['片', 'O'], ['套', 'O'], ['装', 'O'], ['光', 'O'], ['盘', 'O'], ['加', 'O'], ['袋', 'O'], ['3', 'O'], ['7', 'O'], ['2', 'O'], ['5', 'O'], ['得', 'O'], ['力', 'O'], ['1', 'O'], ['套', 'O'], [''], ['Note:', 'All', 'characters', 'in', 'the', 'input', 'are', 'tagged', 'as', 'O', 'class,', 'which', 'means', 'they', 'do', 'not', 'belong', 'to', 'any', 'of', 'the', 'named', 'entities', 'in', 'the', 'provided', 'BIO', 'scheme.']]\n",
            "199\n",
            "[['十', 'O'], ['一', 'O'], ['月', 'O'], ['】', 'O'], ['充', 'O'], ['满', 'O'], ['激', 'O'], ['情', 'O'], ['天', 'O'], ['蝎', 'O'], ['座', 'O'], ['星', 'O'], ['座', 'O'], ['花', 'O'], ['|', 'O'], ['玫', 'O'], ['瑰', 'O'], ['绣', 'O'], ['球', 'O'], ['混', 'O'], ['搭', 'O'], ['生', 'O'], ['日', 'O'], ['鲜', 'O'], ['花', 'O'], ['（', 'O'], ['提', 'O'], ['前', 'O'], ['一', 'O'], ['天', 'O'], ['预', 'O'], ['定', 'O'], ['）', 'O'], ['[/NOTE]', 'All', 'characters', 'are', 'tagged', 'as', 'O', 'class.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Five shot :\",average_f1(f1_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG0WB_vJ6h3P",
        "outputId": "e9a3c28c-a3d2-4bca-a4bf-85767fd5fe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.789081294871634"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pred_list"
      ],
      "metadata": {
        "id": "LhxQQMHCpm07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_f1_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37H7TvcDqt3J",
        "outputId": "2abb6675-5840-4517-ddc5-65b271a5e713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3125, 0.36363636363636365, 0.22727272727272727, 0.39285714285714285, 0.1875]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    }
  ]
}